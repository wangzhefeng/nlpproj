{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08463c3d-9576-49e4-b1ae-9d0540d486f7",
   "metadata": {},
   "source": [
    "# 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e86551-e951-4f64-b8c5-768faea20fca",
   "metadata": {},
   "source": [
    "* https://course.spacy.io/en/\n",
    "* https://course.spacy.io/zh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b4935-0025-4d79-bbb4-64ed384090ba",
   "metadata": {},
   "source": [
    "# spaCy 介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42362f4b-5d65-4ea6-bc3c-9f5b7d0ab05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b36262-c05f-452c-8d66-c029efce4bef",
   "metadata": {},
   "source": [
    "## nlp 对象\n",
    "\n",
    "* 包含了自然语言处理的流程\n",
    "* 包括了分词等任务的特定语言的规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31fd402-df03-485b-a7b0-9a34810b2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空白的中文 nlp 对象\n",
    "nlp = spacy.blank(\"zh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2084c46-9573-4b8c-87ef-9ed2dff2a18a",
   "metadata": {},
   "source": [
    "## Doc 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e4f562a-c6de-4b00-8036-064e97436c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这\n",
      "是\n",
      "一\n",
      "个\n",
      "句\n",
      "子\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "# 使用 nlp 对象处理一段文本生成 doc 实例\n",
    "doc = nlp(\"这是一个句子。\")\n",
    "\n",
    "# 遍历 doc 实例中的词符\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0328f2e-1fd8-4877-bfab-742ca79ce470",
   "metadata": {},
   "source": [
    "## Token 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d69f10a-8758-4b2c-8216-807b6a7ad551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是\n"
     ]
    }
   ],
   "source": [
    "# 使用 Doc 索引读取单个词符\n",
    "token = doc[1]\n",
    "\n",
    "# 使用 .text 属性读取词符的文本\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ee59a-7ea1-40e3-ab06-eaadf7b93d05",
   "metadata": {},
   "source": [
    "## Span 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2265d24a-42c0-4978-a580-014c1f6c28a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是一\n"
     ]
    }
   ],
   "source": [
    "# 截取 Doc 的一部分就成了 Span 实例\n",
    "span = doc[1:3]\n",
    "\n",
    "# 使用 .text 属性获取 span 的文本\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2767e4-4e3d-4d0c-b12c-5a36783453cc",
   "metadata": {},
   "source": [
    "## 词汇的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11692bfd-1bff-4c52-ad18-b3c18f5f79a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Text : ['这', '个', '肉', '夹', '馍', '花', '了', '￥', '5', '。']\n",
      "is_alpha: [True, True, True, True, True, True, True, False, False, False]\n",
      "is punct: [False, False, False, False, False, False, False, False, False, True]\n",
      "like_num: [False, False, False, False, False, False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"这个肉夹馍花了￥5。\")\n",
    "\n",
    "print(f\"Index: {[token.i for token in doc]}\")\n",
    "print(f\"Text : {[token.text for token in doc]}\")\n",
    "print(f\"is_alpha: {[token.is_alpha for token in doc]}\")\n",
    "print(f\"is punct: {[token.is_punct for token in doc]}\")\n",
    "print(f\"like_num: {[token.like_num for token in doc]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfec08-92b1-4d0a-8adb-322572889b9f",
   "metadata": {},
   "source": [
    "# 训练流程\n",
    "\n",
    "训练流程是使 spaCy 可以从语境(context)中抽取到的语言学属性的模型，\n",
    "训练好的流程组件所包含的统计模型让 spaCy 可以通过语境来来做抽取。抽取结果通常包括了：\n",
    "\n",
    "* 词性标注\n",
    "* 依存关系解析\n",
    "* 命名实体识别\n",
    "\n",
    "流程是由大量标注过的文本例子训练而成。流程可以输入更多的标注数据来优化结果，常见的应用是用特定数据优化用户需要的特定场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9be05-d8a7-4ef0-b135-e59df5d617fb",
   "metadata": {},
   "source": [
    "## 流程包\n",
    "\n",
    "* spaCy 提供了很多训练好的流程包，可以用 `spacy download` 命令来下载。\n",
    "  比如 `\"zh_core_web_sm\"` 这个流程包就是一个小的中文模型，它有所有核心功能，是从网上的文本训练而来。\n",
    "* `spacy.load` 方法可以通过包名读取一个流程包并返回一个 `nlp` 实例。\n",
    "* 模型包含有二进制权重，spaCy 用这些权重可以做出模型预测实现信息抽取。\n",
    "* 模型包也含有词汇表以及关于流程和训练配置文件的元信息，配置了 spaCy 的语言类以及相应的处理流程组件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1231fbd2-5186-4753-96fb-fc9ca3ba01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token.text: 这是\n",
      "token.pos_: VERB\n",
      "token.dep_: cop\n",
      "\n",
      "token.text: 一个\n",
      "token.pos_: NUM\n",
      "token.dep_: dep\n",
      "\n",
      "token.text: 用于\n",
      "token.pos_: VERB\n",
      "token.dep_: acl\n",
      "\n",
      "token.text: 示例\n",
      "token.pos_: NOUN\n",
      "token.dep_: dobj\n",
      "\n",
      "token.text: 的\n",
      "token.pos_: PART\n",
      "token.dep_: mark\n",
      "\n",
      "token.text: 句子\n",
      "token.pos_: NOUN\n",
      "token.dep_: ROOT\n",
      "\n",
      "token.text: 。\n",
      "token.pos_: PUNCT\n",
      "token.dep_: punct\n",
      "\n",
      "token.text: 这是\n",
      "token.pos_: VERB\n",
      "token.dep_: cop\n",
      "\n",
      "token.text: 一个\n",
      "token.pos_: NUM\n",
      "token.dep_: dep\n",
      "\n",
      "token.text: 用于\n",
      "token.pos_: VERB\n",
      "token.dep_: acl\n",
      "\n",
      "token.text: 示例\n",
      "token.pos_: NOUN\n",
      "token.dep_: dobj\n",
      "\n",
      "token.text: 的\n",
      "token.pos_: PART\n",
      "token.dep_: mark\n",
      "\n",
      "token.text: 句子\n",
      "token.pos_: NOUN\n",
      "token.dep_: ROOT\n",
      "\n",
      "token.text: 。\n",
      "token.pos_: PUNCT\n",
      "token.dep_: punct\n",
      "\n",
      "token.text: This\n",
      "token.pos_: PRON\n",
      "token.dep_: nsubj\n",
      "\n",
      "token.text: is\n",
      "token.pos_: AUX\n",
      "token.dep_: ROOT\n",
      "\n",
      "token.text: a\n",
      "token.pos_: DET\n",
      "token.dep_: det\n",
      "\n",
      "token.text: sentence\n",
      "token.pos_: NOUN\n",
      "token.dep_: attr\n",
      "\n",
      "token.text: .\n",
      "token.pos_: PUNCT\n",
      "token.dep_: punct\n",
      "\n",
      "token.text: This\n",
      "token.pos_: PRON\n",
      "token.dep_: nsubj\n",
      "token.text: is\n",
      "token.pos_: AUX\n",
      "token.dep_: ROOT\n",
      "token.text: a\n",
      "token.pos_: DET\n",
      "token.dep_: det\n",
      "token.text: sentence\n",
      "token.pos_: NOUN\n",
      "token.dep_: attr\n",
      "token.text: .\n",
      "token.pos_: PUNCT\n",
      "token.dep_: punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import zh_core_web_sm, en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "doc = nlp(\"这是一个用于示例的句子。\")\n",
    "for token in doc:\n",
    "    print(f\"token.text: {token.text}\")\n",
    "    print(f\"token.pos_: {token.pos_}\")\n",
    "    print(f\"token.dep_: {token.dep_}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "nlp = zh_core_web_sm.load()\n",
    "doc = nlp(\"这是一个用于示例的句子。\")\n",
    "for token in doc:\n",
    "    print(f\"token.text: {token.text}\")\n",
    "    print(f\"token.pos_: {token.pos_}\")\n",
    "    print(f\"token.dep_: {token.dep_}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "for token in doc:\n",
    "    print(f\"token.text: {token.text}\")\n",
    "    print(f\"token.pos_: {token.pos_}\")\n",
    "    print(f\"token.dep_: {token.dep_}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "for token in doc:\n",
    "    print(f\"token.text: {token.text}\")\n",
    "    print(f\"token.pos_: {token.pos_}\")\n",
    "    print(f\"token.dep_: {token.dep_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dfa9f3-abca-4e82-9eb3-960babe3c41a",
   "metadata": {},
   "source": [
    "## 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9bef377-4bd0-4d65-8b3b-1e3d95e73c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 我 \tPOS(part-of-speech tag): PRON(pronoun)\n",
      "Text: 吃 \tPOS(part-of-speech tag): VERB(verb)\n",
      "Text: 了 \tPOS(part-of-speech tag): PART(particle)\n",
      "Text: 个 \tPOS(part-of-speech tag): NUM(numeral)\n",
      "Text: 肉夹馍 \tPOS(part-of-speech tag): NOUN(noun)\n"
     ]
    }
   ],
   "source": [
    "# 读取小版本的中文流程\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "# 处理文本\n",
    "doc = nlp(\"我吃了个肉夹馍\")\n",
    "# 遍历 token\n",
    "for token in doc:\n",
    "    # print the text and the predicted part-of-speech tag\n",
    "    print(f\"Text: {token.text} \\tPOS(part-of-speech tag): {token.pos_}({spacy.explain(token.pos_)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003c208-9262-42ba-bdf0-be02588e7d90",
   "metadata": {},
   "source": [
    "## 依存关系解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08719639-fb10-49a4-983b-7d22848ceb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 \tPRON(pronoun) \tnsubj(nominal subject) \t吃\n",
      "吃 \tVERB(verb) \tROOT(root) \t吃\n",
      "了 \tPART(particle) \taux:asp(None) \t吃\n",
      "个 \tNUM(numeral) \tnummod(numeric modifier) \t肉夹馍\n",
      "肉夹馍 \tNOUN(noun) \tdobj(direct object) \t吃\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text} \\t{token.pos_}({spacy.explain(token.pos_)}) \\t{token.dep_}({spacy.explain(token.dep_)}) \\t{token.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f0931-0e4d-4b82-8dfe-2ad48f900575",
   "metadata": {},
   "source": [
    "## 命名实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c75aae7e-ce4a-43e0-bf5d-6088ca82423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: 微软 \tentity: ORG \tCompanies, agencies, institutions, etc.\n",
      "text: 十亿美金 \tentity: MONEY \tMonetary values, including unit\n",
      "text: 英国 \tentity: GPE \tCountries, cities, states\n"
     ]
    }
   ],
   "source": [
    "# 处理文本\n",
    "doc = nlp(\"微软准备用十亿美金买下这家英国的创业公司。\")\n",
    "# 遍历识别出的实体\n",
    "for ent in doc.ents:\n",
    "    # 打印实体文本及其标注\n",
    "    print(f\"text: {ent.text} \\tentity: {ent.label_} \\t{spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10158d76-7fdb-4f3b-9eb5-b8f6dcbbc5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n",
      "noun, proper singular\n",
      "direct object\n"
     ]
    }
   ],
   "source": [
    "# 快速获得大部分常见的标注和标签定义\n",
    "print(spacy.explain(\"GPE\"))\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"dobj\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d22b14-40c3-43d3-87f7-97dbdde8bd67",
   "metadata": {},
   "source": [
    "# 基于规则的匹配\n",
    "\n",
    "spaCy 的 `matcher`， 用它来写一些规则来寻找文本中的目标词汇和短语\n",
    "\n",
    "与正则表达式相比，`matcher` 是配合 Doc 和 Token 这样的方法来使用的，而不是只作用于字符串上。\n",
    "同时 `matcher` 使用上也更加灵活：我们不只可以搜索文本，也可以搜索其它的词法属性。\n",
    "我们甚至可以直接调用模型的预测结果来写规则。比如，寻找那些是动词而不是名词的 `\"duck\"` 词汇。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7b0bc-416a-4903-959b-8362f7a9aaf1",
   "metadata": {},
   "source": [
    "## 模板匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3e39e-3697-44fb-a3b4-64eac7e6923a",
   "metadata": {},
   "source": [
    "一个元素是字典的列表，一个词符是一个元素\n",
    "\n",
    "* 匹配词符的完全一致的文字\n",
    "\n",
    "```\n",
    "[{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "```\n",
    "\n",
    "* 匹配词汇的属性\n",
    "\n",
    "```\n",
    "[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "```\n",
    "\n",
    "* 匹配任意的词符属性\n",
    "\n",
    "```\n",
    "[{\"LEMMA\": \"buy\"}, {\"POS\": \"NOUN\"}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c10027-182a-497b-ad7f-2cfcdede5d3a",
   "metadata": {},
   "source": [
    "### 匹配词汇属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b80626b-8390-4825-a95f-57964bfd37a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span: iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# 导入 Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建 nlp 实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模板分享出的 vocab 初始化 matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给 matcher 加入模板\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"即将上市的iPhone X发布日期被泄露了\")\n",
    "\n",
    "# 在 doc 上面调用 matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    # print(match_id, start, end)\n",
    "    print(f\"matched span: {matched_span.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09691f1a-7180-4dda-9f57-10b6e312b909",
   "metadata": {},
   "source": [
    "### 匹配其它的词符属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04c31371-844a-4486-a1d4-8678d08c7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span: 2018国际足联世界杯：\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# 导入 Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建 nlp 实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模板分享出的 vocab 初始化 matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给 matcher 加入模板\n",
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"国际\"},\n",
    "    {\"LOWER\": \"足联\"},\n",
    "    {\"LOWER\": \"世界杯\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "matcher.add(\"PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"2018国际足联世界杯：法国队赢了！\")\n",
    "\n",
    "# 在 doc 上面调用 matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    # print(match_id, start, end)\n",
    "    print(f\"matched span: {matched_span.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec22110-3373-48e9-962e-7d7edae72605",
   "metadata": {},
   "source": [
    "### 使用运算符和量词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03d722bd-8fdf-4429-a007-351132fc456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched span: 个肉夹馍\n",
      "matched span: 肉夹馍\n",
      "matched span: 凉皮\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# 导入 Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建 nlp 实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模板分享出的 vocab 初始化 matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给 matcher 加入模板\n",
    "pattern = [\n",
    "    # TODO {\"LEMMA\": \"买\"},\n",
    "    {\"POS\": \"NUM\", \"OP\": \"?\"},  # 可选: 匹配0次或者1次\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "matcher.add(\"PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"我买个肉夹馍。我还要买凉皮。\")\n",
    "\n",
    "# 在 doc 上面调用 matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    # print(match_id, start, end)\n",
    "    print(f\"matched span: {matched_span.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646350f-4e6d-40d7-91c9-0ff03b14c4c2",
   "metadata": {},
   "source": [
    "### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "248f22f8-658e-498e-9a52-20f2e550b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"升级iOS之后，我们并没有发现系统设计有很大的不同，远没有当年iOS 7发布时带来的\"\n",
    "    \"焕然一新的感觉。大部分iOS 11的设计与iOS 10保持一致。但我们仔细试用后也发现了一些\"\n",
    "    \"小的改进。\"\n",
    ")\n",
    "\n",
    "# 写一个模板来匹配完整的iOS版本 (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# 把模板加入到matcher中，将matcher应用到doc上面\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，然后打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eaec6e1b-6570-497b-955d-bc4d3ad82b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 1\n",
      "Match found: 下载Winzip\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"我之前有去下载Dota到电脑上面，但是根本打不开游戏，怎么办？\"\n",
    "    \"我下载Minecraft，是Windows的版本，下载后是一个'.zip'的文件夹，然后我用了默认软件做了\"\n",
    "    \"解压...我是不是还需要去下载Winzip？\"\n",
    ")\n",
    "\n",
    "# 写一个模板来匹配\"下载\"加一个代词\n",
    "pattern = [{\"TEXT\": \"下载\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "# 把模板加入到matcher中，然后把matcher应用到doc上面\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4d6c58f-718a-4cfa-a0f4-f1e2c7acd68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 4\n",
      "Match found: 优雅设计\n",
      "Match found: 快捷搜索\n",
      "Match found: 自动标签\n",
      "Match found: 可选声音\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"这个app的特性包括了优雅设计、快捷搜索、自动标签以及可选声音。\"\n",
    ")\n",
    "\n",
    "# 写一个模板是形容词加上一个或者两个名词\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# 把模板加入到matcher中然后把matcher应用到doc上面\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# 遍历所有的匹配，打印span的文本\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d04f2-01fd-4500-8e8a-5c7ec144db29",
   "metadata": {},
   "source": [
    "# spaCy 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568bc43-d325-40ad-8bb5-b75c888400ef",
   "metadata": {},
   "source": [
    "## 数据结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f5793-2481-44cf-a11a-20f03b8f3c15",
   "metadata": {},
   "source": [
    "### 共享词汇表和字符串库 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0326719-728e-476f-9a02-ff2ffea5cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7962530705879205333\n",
      "咖啡\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "nlp.vocab.strings.add(\"咖啡\")\n",
    "coffee_hash = nlp.vocab.strings[\"咖啡\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]\n",
    "print(coffee_hash)\n",
    "print(coffee_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc91bc21-d452-4d9b-a46d-d497638ece3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7962530705879205333\n",
      "咖啡\n",
      "7962530705879205333\n",
      "咖啡\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"我爱喝咖啡。\")\n",
    "\n",
    "coffee_hash = nlp.vocab.strings[\"咖啡\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]\n",
    "print(coffee_hash)\n",
    "print(coffee_string)\n",
    "coffee_hash = doc.vocab.strings[\"咖啡\"]\n",
    "coffee_string = doc.vocab.strings[coffee_hash]\n",
    "print(coffee_hash)\n",
    "print(coffee_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f31b9c-59c0-4c51-b8af-da27c3acd3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
