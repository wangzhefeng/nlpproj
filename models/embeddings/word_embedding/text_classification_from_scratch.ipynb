{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-sport",
   "metadata": {},
   "source": [
    "# 1.Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "running-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-issue",
   "metadata": {},
   "source": [
    "# 2.数据加载、探索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-supervision",
   "metadata": {},
   "source": [
    "## 2.1 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "typical-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README     imdb.vocab imdbEr.txt \u001b[1m\u001b[36mtest\u001b[m\u001b[m       \u001b[1m\u001b[36mtrain\u001b[m\u001b[m\n",
      "labeledBow.feat \u001b[1m\u001b[36mneg\u001b[m\u001b[m             \u001b[1m\u001b[36mpos\u001b[m\u001b[m             urls_neg.txt    urls_pos.txt\n",
      "labeledBow.feat \u001b[1m\u001b[36mpos\u001b[m\u001b[m             unsupBow.feat   urls_pos.txt\n",
      "\u001b[1m\u001b[36mneg\u001b[m\u001b[m             \u001b[1m\u001b[36munsup\u001b[m\u001b[m           urls_neg.txt    urls_unsup.txt\n",
      "Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you!"
     ]
    }
   ],
   "source": [
    "# !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "# !tar -xf aclImdb_v1.tar.gz\n",
    "!ls aclImdb\n",
    "!ls aclImdb/test\n",
    "!ls aclImdb/train\n",
    "!cat aclImdb/train/pos/6248_7.txt\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-spray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(config.data_dir, \"train\"),\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 1337,\n",
    ")\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(config.data_dir, \"train\"),\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 1337,\n",
    ")\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    os.path.join(config.data_dir, \"test\"),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "print(f\"Number of batches in raw_train_ds: {tf.data.experimental.cardinality(raw_train_ds)}\")\n",
    "print(f\"Number of batches in raw_val_ds: {tf.data.experimental.cardinality(raw_val_ds)}\")\n",
    "print(f\"Number of batches in raw_test_ds: {tf.data.experimental.cardinality(raw_test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-sally",
   "metadata": {},
   "source": [
    "## 2.2 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "raised-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_batch.numpy()[i]=\n",
      "b'I rented this horrible movie. The worst think I have ever seen. I believe a 1st grade class could have done a better job. The worse film I have ever seen and I have seen some bad ones. Nothing scary except I paid 1.50 to rent it and that was 1.49 too much. The acting is horrible, the characters are worse and the film is just a piece of trash. The slauther house scenes are so low budget that it makes a B movied look like an Oscar candidate. All I can say is if you wnat to waste a good evening and a little money go rent this horrible flick. I would rather watch killer clowns from outer space while sitting in a bucket of razors than sit through this flop again'\n",
      "label_batch.numpy()[i]=\n",
      "0\n",
      "text_batch.numpy()[i]=\n",
      "b\"I spent almost two hours watching a movie that I thought, with all the good actors in it, would be worth watching. I couldn't believe it when the movie ended and I had absolutely no idea what had happened.....I was mad because I could have used that time doing something else....I tried to figure it all out, but really had no clue. Thanks to those who figured it out and have explained it....right or wrong, it's better than not knowing anything!! Who was the lady in the movie with dark hair that we saw a couple of times driving away? How did First Lady know that her husband was cheating on her? At the end of the movie Kate said she would eventually find out the truth. Does this mean that we're going to be subjected to End Game 2?\"\n",
      "label_batch.numpy()[i]=\n",
      "0\n",
      "text_batch.numpy()[i]=\n",
      "b\"As incredible as it may seem, Gojoe is an anime- and Hong Kong-inspired samurai action flick with a pacifistic message. This ankle of the film is effectively portrayed through the protagonist (a great acting job done by Daisuke Ryu), a killer-turned-to-boddhist-monk Benkei. Benkei has sworn never to kill again, but he still takes up the sword to fight what he thinks is a demon invasion...<br /><br />Gojoe is a film difficult to rate. It's visual imagery is stunningly crafted and beautiful, but it uses too much trickery (circling camera and high speed drives, expressionistic shots, leeched colors, digital effects etc.), so the end result is somewhat tiring. That said, the beginning and the ending of the film are nevertheless both elegant and powerful. If only the director Sogo Ishii would have been wise enough not to overuse his bag of tricks.<br /><br />Other problem with Gojoe is the amount of violence. For a film with such an anti-violent message Gojoe wastes way too much energy and screen time to depict the endless battle scenes. Also, the way the violence is shown is always on the edge of being self-indulgent; in fact, a blood shower against the night sky seems to be one of the films signature images. Luckily, Ishii is wise enough to show the ugly, tragic side of violence as well. Still, it seems that Ishii is not sure whether he's making a traditional action film or a deeply moral allegory. The audience can't be sure of this, either, until the very end of the film. The powerful (albeit cynical) ending is what saves Gojoe; it clearly emphasizes that this film is something more than a mere gore-fest.\"\n",
      "label_batch.numpy()[i]=\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f\"text_batch.numpy()[i]=\\n{text_batch.numpy()[i]}\")\n",
    "        print(f\"label_batch.numpy()[i]=\\n{label_batch.numpy()[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-thomas",
   "metadata": {},
   "source": [
    "## 2.3 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overhead-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    \"\"\"\n",
    "    # 删除 \"<br />\"\n",
    "    \"\"\"\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    standardization_data = tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "    return standardization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessible-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Let's make a text-only dataset (no labels):\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "\n",
    "# Let's call `adapt`:\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-display",
   "metadata": {},
   "source": [
    "## 2.4 文本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "previous-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "# 数据向量化\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "# async prefetching / buffering\n",
    "train_ds = train_ds.cache().prefetch(buffer_size = 10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size = 10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-planet",
   "metadata": {},
   "source": [
    "# 3.模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-arrow",
   "metadata": {},
   "source": [
    "## 3.1 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "geological-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (None,), dtype = \"int64\")\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv1D(128, 7, padding = \"valid\", activation = \"relu\", strides = 3)(x)\n",
    "x = layers.Conv1D(128, 7, padding = \"valid\", activation = \"relu\", strides = 3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation = \"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(1, activation = \"sigmoid\", name = \"predictions\")(x)\n",
    "model = tf.keras.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-flashing",
   "metadata": {},
   "source": [
    "## 3.2 模型编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medieval-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-knitting",
   "metadata": {},
   "source": [
    "## 3.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stable-river",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.4794 - accuracy: 0.7330 - val_loss: 0.3235 - val_accuracy: 0.8610\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 78s 124ms/step - loss: 0.2206 - accuracy: 0.9122 - val_loss: 0.2954 - val_accuracy: 0.8740\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.1169 - accuracy: 0.9567 - val_loss: 0.3828 - val_accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1550548e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "model.fit(train_ds, validation_data = val_ds, epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-shape",
   "metadata": {},
   "source": [
    "## 3.4 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "political-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4272 - accuracy: 0.8529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.427167147397995, 0.8528800010681152]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-doubt",
   "metadata": {},
   "source": [
    "# 4.构建端到端模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bigger-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4272 - accuracy: 0.8529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4271673858165741, 0.8528800010681152]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (1,), dtype = \"string\")\n",
    "indices = vectorize_layer(inputs)\n",
    "outputs = model(indices)\n",
    "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "end_to_end_model.evaluate(raw_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
